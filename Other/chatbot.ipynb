{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dftCwDU76m5d",
        "outputId": "93acb710-7f9b-4ba3-b1d3-7c7b42f99b72"
      },
      "outputs": [],
      "source": [
        "# !gdown 1MmJtib8_P0i5kMrIyEfdgDH_Okwlr8aY #download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "G0p5Bj1Hx-io"
      },
      "outputs": [],
      "source": [
        "# Import Library\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "import random\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dropout, GlobalMaxPool1D, Bidirectional, Conv1D, MaxPooling1D, Bidirectional, GRU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Flatten, Dense, GlobalMaxPool1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "tG5BIhNYyHdU"
      },
      "outputs": [],
      "source": [
        "with open('waste_management3.json', encoding='utf-8') as content:\n",
        "  data = json.load(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwxUoXK3zRcm",
        "outputId": "a2aa3e14-e066-497c-bc99-8b4ef34dd248"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\biman\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\biman\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\biman\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Package sentence tokenizer\n",
        "nltk.download('punkt')\n",
        "# Package lemmatization\n",
        "nltk.download('wordnet')\n",
        "# Package multilingual wordnet data\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "w-QY9K7hyLTk"
      },
      "outputs": [],
      "source": [
        "# Mendapatkan semua data ke dalam list\n",
        "tags = [] # data tag\n",
        "inputs = [] # data input atau pattern\n",
        "responses = {} # data respon\n",
        "words = [] # Data kata\n",
        "classes = [] # Data Kelas atau Tag\n",
        "documents = [] # Data Kalimat Dokumen\n",
        "ignore_words = ['?', '!'] # Mengabaikan tanda spesial karakter\n",
        "\n",
        "for intent in data['intents']:\n",
        "  responses[intent['tag']]=intent['responses']\n",
        "  for lines in intent['patterns']:\n",
        "    inputs.append(lines)\n",
        "    tags.append(intent['tag'])\n",
        "    for pattern in intent['patterns']:\n",
        "      w = nltk.word_tokenize(pattern)\n",
        "      words.extend(w)\n",
        "      documents.append((w, intent['tag']))\n",
        "      # add to our classes list\n",
        "      if intent['tag'] not in classes:\n",
        "        classes.append(intent['tag'])\n",
        "\n",
        "# Konversi data json ke dalam dataframe\n",
        "# data = pd.DataFrame({\"patterns\":inputs, \"tags\":tags})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "jGpnIAWEyP-P"
      },
      "outputs": [],
      "source": [
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(inputs, tags,test_size=0.2, random_state=42)\n",
        "\n",
        "# Konversi data ke dalam dataframe\n",
        "train_data = pd.DataFrame({\"patterns\": X_train, \"tags\": y_train})\n",
        "test_data = pd.DataFrame({\"patterns\": X_test, \"tags\": y_test})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZSRrK9dtmDo",
        "outputId": "18670a24-6c08-4a93-ef37-422a66dac2c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 189 entries, 0 to 188\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   patterns  189 non-null    object\n",
            " 1   tags      189 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 3.1+ KB\n"
          ]
        }
      ],
      "source": [
        "train_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5afUT0eBtx2p",
        "outputId": "881f56e3-2487-4dbb-8127-ba6f6206587c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 48 entries, 0 to 47\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   patterns  48 non-null     object\n",
            " 1   tags      48 non-null     object\n",
            "dtypes: object(2)\n",
            "memory usage: 896.0+ bytes\n"
          ]
        }
      ],
      "source": [
        "test_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QxA3cv9_yODX",
        "outputId": "6999e601-e256-42ad-e94d-67f8fe615bca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patterns</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Apa manfaat dari pengolahan limbah sampah?</td>\n",
              "      <td>manfaat_pengolahan_limbah_sampah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Apa itu pengolahan limbah kaca?</td>\n",
              "      <td>pengolahan_limbah_kaca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Berikan penjelasan nilai yang dihasilkan dari ...</td>\n",
              "      <td>nilai_pengolahan_kaca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jelaskan langkah dalam pengolahan limbah?</td>\n",
              "      <td>langkah_pengolahan_limbah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bagaimana cara menghasilkan biogas dari limbah?</td>\n",
              "      <td>pengolahan_biogas</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            patterns  \\\n",
              "0         Apa manfaat dari pengolahan limbah sampah?   \n",
              "1                    Apa itu pengolahan limbah kaca?   \n",
              "2  Berikan penjelasan nilai yang dihasilkan dari ...   \n",
              "3          jelaskan langkah dalam pengolahan limbah?   \n",
              "4    Bagaimana cara menghasilkan biogas dari limbah?   \n",
              "\n",
              "                               tags  \n",
              "0  manfaat_pengolahan_limbah_sampah  \n",
              "1            pengolahan_limbah_kaca  \n",
              "2             nilai_pengolahan_kaca  \n",
              "3         langkah_pengolahan_limbah  \n",
              "4                 pengolahan_biogas  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hLv2UfORyAOU",
        "outputId": "5555b289-128c-46f9-a53e-c584eb851da9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patterns</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>apa daur ulang limbah sampah itu penting? kena...</td>\n",
              "      <td>pentingnya_daur_ulang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WasteBot</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Manfaat dari pengolahan limbah kaca apa saja?</td>\n",
              "      <td>manfaat_pengolahan_kaca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>berikan jenis atau contoh limbah sampah yang b...</td>\n",
              "      <td>jenis_sampah_daur_ulang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pagi</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            patterns                     tags\n",
              "0  apa daur ulang limbah sampah itu penting? kena...    pentingnya_daur_ulang\n",
              "1                                           WasteBot                 greeting\n",
              "2      Manfaat dari pengolahan limbah kaca apa saja?  manfaat_pengolahan_kaca\n",
              "3  berikan jenis atau contoh limbah sampah yang b...  jenis_sampah_daur_ulang\n",
              "4                                               pagi                 greeting"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "cQeG3ZFEyRLy"
      },
      "outputs": [],
      "source": [
        "train_data['patterns'] = train_data['patterns'].apply(lambda wrd: [ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
        "train_data['patterns'] = train_data['patterns'].apply(lambda wrd: ''.join(wrd))\n",
        "test_data['patterns'] = test_data['patterns'].apply(lambda wrd: [ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
        "test_data['patterns'] = test_data['patterns'].apply(lambda wrd: ''.join(wrd))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "KtXY6PSl5j-P"
      },
      "outputs": [],
      "source": [
        "# Inisialisasi Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Fungsi untuk melakukan lemmatization pada kata-kata dalam kalimat\n",
        "def lemmatize_text(text):\n",
        "    tokens = nltk.word_tokenize(text)  # Tokenisasi kata-kata dalam kalimat\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Lemmatization\n",
        "    lemmatized_text = ' '.join(lemmatized_tokens)  # Menggabungkan kembali kata-kata menjadi kalimat\n",
        "    return lemmatized_text\n",
        "\n",
        "# Contoh penggunaan fungsi lemmatize_text pada dataset\n",
        "train_data['patterns'] = train_data['patterns'].apply(lemmatize_text)\n",
        "test_data['patterns'] = test_data['patterns'].apply(lemmatize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Oj_OfY-Jyckg"
      },
      "outputs": [],
      "source": [
        "# Tokenize the data (Tokenisasi Data)\n",
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(train_data['patterns'])\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(train_data['patterns'])\n",
        "x_test = tokenizer.texts_to_sequences(test_data['patterns'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "lcMsfSegyisb"
      },
      "outputs": [],
      "source": [
        "# Apply padding\n",
        "max_sequence_length = max(len(seq) for seq in x_train + x_test)\n",
        "x_train = pad_sequences(x_train, maxlen=max_sequence_length)\n",
        "x_test = pad_sequences(x_test, maxlen=max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "9DODB0svyseu"
      },
      "outputs": [],
      "source": [
        "# Combine tags from train_data and test_data\n",
        "all_tags = list(set(train_data['tags']) | set(test_data['tags']))\n",
        "\n",
        "# Encoding the outputs\n",
        "le = LabelEncoder()\n",
        "le.fit(all_tags)\n",
        "\n",
        "y_train = le.transform(train_data['tags'])\n",
        "y_test = le.transform(test_data['tags'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "pBSWgeHhyu42"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset\n",
        "train_dataset = (x_train, y_train)\n",
        "test_dataset = (x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "AQrfnYeMyw8I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 16)]              0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 16, 100)           16600     \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 16, 64)           34048     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 16, 128)          49920     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                102450    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 37)                1887      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 204,905\n",
            "Trainable params: 204,905\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Creating the model\n",
        "# Menambahkan regularisasi L2\n",
        "regularization = regularizers.l2(0.01)\n",
        "\n",
        "# Mengubah tingkat dropout menjadi 0.5\n",
        "dropout_rate = 0.5\n",
        "\n",
        "# Mendefinisikan input layer\n",
        "i = Input(shape=(max_sequence_length,))\n",
        "\n",
        "# Embedding layer\n",
        "embedding_size = 100\n",
        "x = Embedding(len(tokenizer.word_index) + 1, embedding_size)(i)\n",
        "\n",
        "# Bidirectional LSTM layer\n",
        "lstm_units = 32\n",
        "x = Bidirectional(LSTM(lstm_units, return_sequences=True))(x)\n",
        "\n",
        "# Bidirectional GRU layer\n",
        "gru_units = 64\n",
        "x = Bidirectional(GRU(gru_units, return_sequences=True))(x)\n",
        "\n",
        "# Flatten layer\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Dense layer with L2 regularization\n",
        "dense_units = 50\n",
        "x = Dense(dense_units, activation='relu', kernel_regularizer=regularization)(x)\n",
        "x = Dropout(dropout_rate)(x)\n",
        "\n",
        "# Output layer\n",
        "num_classes = len(classes)\n",
        "x = Dense(num_classes, activation=\"softmax\")(x)\n",
        "model = Model(i, x)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "gDiz8PXGuRWZ"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    # Define the method that checks the accuracy at the end of each epoch\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('val_accuracy') > 0.8:\n",
        "            print(\"\\nReached 0.7 val acc so cancelling training!\")\n",
        "\n",
        "            # Stop training once the above condition is met\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "r-DsQhQ06R3M"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "# Instantiate the callback class\n",
        "cb = myCallback()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "WBF2qrzFy0AR"
      },
      "outputs": [],
      "source": [
        "# Compiling the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "iBQDyHxZy2Ku"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "6/6 [==============================] - 8s 283ms/step - loss: 4.4636 - accuracy: 0.0370 - val_loss: 4.3247 - val_accuracy: 0.0208\n",
            "Epoch 2/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 4.2128 - accuracy: 0.0370 - val_loss: 4.1132 - val_accuracy: 0.0417\n",
            "Epoch 3/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 4.0083 - accuracy: 0.0582 - val_loss: 3.9478 - val_accuracy: 0.0833\n",
            "Epoch 4/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 3.8570 - accuracy: 0.0529 - val_loss: 3.8029 - val_accuracy: 0.0833\n",
            "Epoch 5/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 3.7091 - accuracy: 0.0635 - val_loss: 3.6987 - val_accuracy: 0.1042\n",
            "Epoch 6/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 3.6110 - accuracy: 0.1005 - val_loss: 3.6185 - val_accuracy: 0.1042\n",
            "Epoch 7/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 3.5532 - accuracy: 0.0847 - val_loss: 3.5395 - val_accuracy: 0.1042\n",
            "Epoch 8/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 3.4842 - accuracy: 0.0952 - val_loss: 3.4867 - val_accuracy: 0.0833\n",
            "Epoch 9/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 3.4143 - accuracy: 0.0582 - val_loss: 3.4630 - val_accuracy: 0.0833\n",
            "Epoch 10/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 3.2979 - accuracy: 0.1270 - val_loss: 3.4735 - val_accuracy: 0.0833\n",
            "Epoch 11/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 3.2460 - accuracy: 0.1217 - val_loss: 3.4375 - val_accuracy: 0.1042\n",
            "Epoch 12/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 3.1356 - accuracy: 0.1270 - val_loss: 3.4234 - val_accuracy: 0.1250\n",
            "Epoch 13/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 3.1573 - accuracy: 0.1429 - val_loss: 3.3950 - val_accuracy: 0.0833\n",
            "Epoch 14/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 3.1227 - accuracy: 0.1376 - val_loss: 3.3684 - val_accuracy: 0.0833\n",
            "Epoch 15/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 3.0014 - accuracy: 0.1376 - val_loss: 3.3988 - val_accuracy: 0.1042\n",
            "Epoch 16/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 3.0659 - accuracy: 0.1323 - val_loss: 3.3235 - val_accuracy: 0.1250\n",
            "Epoch 17/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 2.8998 - accuracy: 0.1376 - val_loss: 3.2697 - val_accuracy: 0.1250\n",
            "Epoch 18/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 2.8782 - accuracy: 0.1799 - val_loss: 3.2263 - val_accuracy: 0.1458\n",
            "Epoch 19/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 2.7246 - accuracy: 0.2222 - val_loss: 3.1551 - val_accuracy: 0.1458\n",
            "Epoch 20/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 2.6141 - accuracy: 0.2116 - val_loss: 3.2586 - val_accuracy: 0.1667\n",
            "Epoch 21/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 2.4916 - accuracy: 0.2275 - val_loss: 3.1733 - val_accuracy: 0.1875\n",
            "Epoch 22/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 2.3309 - accuracy: 0.3704 - val_loss: 3.1157 - val_accuracy: 0.2292\n",
            "Epoch 23/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 2.2612 - accuracy: 0.3757 - val_loss: 3.3011 - val_accuracy: 0.2708\n",
            "Epoch 24/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 2.2249 - accuracy: 0.3492 - val_loss: 3.0890 - val_accuracy: 0.1875\n",
            "Epoch 25/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 2.1384 - accuracy: 0.3810 - val_loss: 3.1076 - val_accuracy: 0.2083\n",
            "Epoch 26/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 1.8725 - accuracy: 0.4656 - val_loss: 2.9162 - val_accuracy: 0.3333\n",
            "Epoch 27/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 1.8530 - accuracy: 0.4868 - val_loss: 2.8957 - val_accuracy: 0.3125\n",
            "Epoch 28/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 1.8641 - accuracy: 0.4497 - val_loss: 3.0923 - val_accuracy: 0.3750\n",
            "Epoch 29/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 1.7154 - accuracy: 0.4974 - val_loss: 2.7797 - val_accuracy: 0.3333\n",
            "Epoch 30/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 1.6368 - accuracy: 0.5556 - val_loss: 2.8578 - val_accuracy: 0.3750\n",
            "Epoch 31/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 1.5281 - accuracy: 0.5503 - val_loss: 2.7638 - val_accuracy: 0.3125\n",
            "Epoch 32/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 1.5973 - accuracy: 0.5714 - val_loss: 2.8478 - val_accuracy: 0.3542\n",
            "Epoch 33/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 1.4161 - accuracy: 0.5979 - val_loss: 2.7496 - val_accuracy: 0.2917\n",
            "Epoch 34/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 1.4556 - accuracy: 0.5608 - val_loss: 2.5248 - val_accuracy: 0.3750\n",
            "Epoch 35/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 1.3997 - accuracy: 0.6138 - val_loss: 2.4955 - val_accuracy: 0.3125\n",
            "Epoch 36/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 1.3223 - accuracy: 0.6508 - val_loss: 2.6831 - val_accuracy: 0.4375\n",
            "Epoch 37/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 1.2827 - accuracy: 0.6508 - val_loss: 2.4153 - val_accuracy: 0.3958\n",
            "Epoch 38/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 1.2184 - accuracy: 0.6720 - val_loss: 2.6653 - val_accuracy: 0.3958\n",
            "Epoch 39/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 1.1657 - accuracy: 0.6772 - val_loss: 2.7298 - val_accuracy: 0.3333\n",
            "Epoch 40/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 1.1180 - accuracy: 0.6614 - val_loss: 2.6444 - val_accuracy: 0.4375\n",
            "Epoch 41/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 1.0462 - accuracy: 0.7407 - val_loss: 2.6731 - val_accuracy: 0.4792\n",
            "Epoch 42/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.8868 - accuracy: 0.7672 - val_loss: 2.8809 - val_accuracy: 0.4792\n",
            "Epoch 43/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 1.0161 - accuracy: 0.7354 - val_loss: 2.6388 - val_accuracy: 0.3958\n",
            "Epoch 44/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.8981 - accuracy: 0.7619 - val_loss: 2.7261 - val_accuracy: 0.5417\n",
            "Epoch 45/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.8556 - accuracy: 0.7989 - val_loss: 2.6198 - val_accuracy: 0.4375\n",
            "Epoch 46/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.8180 - accuracy: 0.8095 - val_loss: 2.6206 - val_accuracy: 0.5208\n",
            "Epoch 47/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.7976 - accuracy: 0.8201 - val_loss: 2.7582 - val_accuracy: 0.5208\n",
            "Epoch 48/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.9262 - accuracy: 0.7672 - val_loss: 2.7763 - val_accuracy: 0.4792\n",
            "Epoch 49/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.7508 - accuracy: 0.8095 - val_loss: 2.6284 - val_accuracy: 0.5833\n",
            "Epoch 50/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.7948 - accuracy: 0.8201 - val_loss: 2.5828 - val_accuracy: 0.4583\n",
            "Epoch 51/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.7954 - accuracy: 0.7989 - val_loss: 2.7547 - val_accuracy: 0.4375\n",
            "Epoch 52/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.7898 - accuracy: 0.8201 - val_loss: 2.7816 - val_accuracy: 0.5208\n",
            "Epoch 53/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.6886 - accuracy: 0.8519 - val_loss: 2.6684 - val_accuracy: 0.4792\n",
            "Epoch 54/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.7233 - accuracy: 0.8148 - val_loss: 2.4925 - val_accuracy: 0.5000\n",
            "Epoch 55/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.7085 - accuracy: 0.8307 - val_loss: 2.6302 - val_accuracy: 0.5833\n",
            "Epoch 56/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.7398 - accuracy: 0.7884 - val_loss: 2.6557 - val_accuracy: 0.5417\n",
            "Epoch 57/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.5813 - accuracy: 0.8942 - val_loss: 2.5232 - val_accuracy: 0.5417\n",
            "Epoch 58/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.7145 - accuracy: 0.8201 - val_loss: 2.9010 - val_accuracy: 0.5417\n",
            "Epoch 59/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.6483 - accuracy: 0.8519 - val_loss: 2.6703 - val_accuracy: 0.5417\n",
            "Epoch 60/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.5732 - accuracy: 0.8942 - val_loss: 2.6130 - val_accuracy: 0.5208\n",
            "Epoch 61/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.5497 - accuracy: 0.8783 - val_loss: 2.8248 - val_accuracy: 0.4583\n",
            "Epoch 62/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.5535 - accuracy: 0.9101 - val_loss: 2.8239 - val_accuracy: 0.6458\n",
            "Epoch 63/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.6145 - accuracy: 0.8466 - val_loss: 2.8855 - val_accuracy: 0.5208\n",
            "Epoch 64/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.5767 - accuracy: 0.8836 - val_loss: 2.8181 - val_accuracy: 0.5208\n",
            "Epoch 65/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.5674 - accuracy: 0.8466 - val_loss: 2.9121 - val_accuracy: 0.4583\n",
            "Epoch 66/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.6030 - accuracy: 0.8571 - val_loss: 3.1993 - val_accuracy: 0.5208\n",
            "Epoch 67/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.5318 - accuracy: 0.8730 - val_loss: 3.0558 - val_accuracy: 0.5417\n",
            "Epoch 68/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.5998 - accuracy: 0.8571 - val_loss: 2.9917 - val_accuracy: 0.5000\n",
            "Epoch 69/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4889 - accuracy: 0.9153 - val_loss: 2.6353 - val_accuracy: 0.5625\n",
            "Epoch 70/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.5480 - accuracy: 0.8889 - val_loss: 2.5743 - val_accuracy: 0.5625\n",
            "Epoch 71/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.5468 - accuracy: 0.8783 - val_loss: 2.6913 - val_accuracy: 0.5208\n",
            "Epoch 72/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4693 - accuracy: 0.8995 - val_loss: 2.8994 - val_accuracy: 0.5833\n",
            "Epoch 73/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.5244 - accuracy: 0.8836 - val_loss: 2.8011 - val_accuracy: 0.5208\n",
            "Epoch 74/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4795 - accuracy: 0.9048 - val_loss: 2.9559 - val_accuracy: 0.4792\n",
            "Epoch 75/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.5220 - accuracy: 0.8730 - val_loss: 2.8971 - val_accuracy: 0.5417\n",
            "Epoch 76/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.4798 - accuracy: 0.9048 - val_loss: 2.8119 - val_accuracy: 0.5208\n",
            "Epoch 77/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4515 - accuracy: 0.8995 - val_loss: 2.8833 - val_accuracy: 0.5208\n",
            "Epoch 78/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4468 - accuracy: 0.9153 - val_loss: 2.7315 - val_accuracy: 0.5417\n",
            "Epoch 79/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4033 - accuracy: 0.9312 - val_loss: 2.6293 - val_accuracy: 0.5833\n",
            "Epoch 80/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4383 - accuracy: 0.9259 - val_loss: 2.6073 - val_accuracy: 0.5625\n",
            "Epoch 81/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4905 - accuracy: 0.8942 - val_loss: 2.7505 - val_accuracy: 0.5000\n",
            "Epoch 82/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4157 - accuracy: 0.9471 - val_loss: 2.7240 - val_accuracy: 0.5000\n",
            "Epoch 83/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3519 - accuracy: 0.9630 - val_loss: 2.5835 - val_accuracy: 0.5000\n",
            "Epoch 84/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4129 - accuracy: 0.9153 - val_loss: 2.5182 - val_accuracy: 0.5417\n",
            "Epoch 85/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3854 - accuracy: 0.9365 - val_loss: 2.4388 - val_accuracy: 0.5417\n",
            "Epoch 86/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4139 - accuracy: 0.9312 - val_loss: 2.5360 - val_accuracy: 0.5417\n",
            "Epoch 87/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3781 - accuracy: 0.9365 - val_loss: 2.8128 - val_accuracy: 0.5625\n",
            "Epoch 88/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3793 - accuracy: 0.9206 - val_loss: 2.7375 - val_accuracy: 0.5833\n",
            "Epoch 89/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3451 - accuracy: 0.9524 - val_loss: 2.6333 - val_accuracy: 0.5417\n",
            "Epoch 90/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3359 - accuracy: 0.9471 - val_loss: 2.8612 - val_accuracy: 0.6042\n",
            "Epoch 91/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.4665 - accuracy: 0.8783 - val_loss: 2.8293 - val_accuracy: 0.5000\n",
            "Epoch 92/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3724 - accuracy: 0.9312 - val_loss: 2.6962 - val_accuracy: 0.4792\n",
            "Epoch 93/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3603 - accuracy: 0.9259 - val_loss: 2.7072 - val_accuracy: 0.5208\n",
            "Epoch 94/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3720 - accuracy: 0.9206 - val_loss: 2.5873 - val_accuracy: 0.5208\n",
            "Epoch 95/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3675 - accuracy: 0.9471 - val_loss: 2.5249 - val_accuracy: 0.5208\n",
            "Epoch 96/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3167 - accuracy: 0.9630 - val_loss: 2.5026 - val_accuracy: 0.5417\n",
            "Epoch 97/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3925 - accuracy: 0.9206 - val_loss: 2.5442 - val_accuracy: 0.5417\n",
            "Epoch 98/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.2944 - accuracy: 0.9577 - val_loss: 2.6130 - val_accuracy: 0.5208\n",
            "Epoch 99/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3367 - accuracy: 0.9365 - val_loss: 2.8646 - val_accuracy: 0.5208\n",
            "Epoch 100/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3447 - accuracy: 0.9312 - val_loss: 2.7465 - val_accuracy: 0.5208\n",
            "Epoch 101/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3052 - accuracy: 0.9577 - val_loss: 2.7117 - val_accuracy: 0.5000\n",
            "Epoch 102/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.4092 - accuracy: 0.9206 - val_loss: 2.6756 - val_accuracy: 0.5208\n",
            "Epoch 103/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3678 - accuracy: 0.9259 - val_loss: 2.7951 - val_accuracy: 0.5000\n",
            "Epoch 104/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3597 - accuracy: 0.9312 - val_loss: 3.0314 - val_accuracy: 0.4583\n",
            "Epoch 105/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3158 - accuracy: 0.9577 - val_loss: 2.6681 - val_accuracy: 0.5625\n",
            "Epoch 106/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.3484 - accuracy: 0.9259 - val_loss: 2.7138 - val_accuracy: 0.5625\n",
            "Epoch 107/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3356 - accuracy: 0.9365 - val_loss: 2.7146 - val_accuracy: 0.4792\n",
            "Epoch 108/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3474 - accuracy: 0.9259 - val_loss: 2.4860 - val_accuracy: 0.5417\n",
            "Epoch 109/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3301 - accuracy: 0.9365 - val_loss: 2.6407 - val_accuracy: 0.5208\n",
            "Epoch 110/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2943 - accuracy: 0.9630 - val_loss: 2.8734 - val_accuracy: 0.5000\n",
            "Epoch 111/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3392 - accuracy: 0.9471 - val_loss: 2.8501 - val_accuracy: 0.5208\n",
            "Epoch 112/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3527 - accuracy: 0.9153 - val_loss: 2.8210 - val_accuracy: 0.5000\n",
            "Epoch 113/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3288 - accuracy: 0.9471 - val_loss: 2.7977 - val_accuracy: 0.5208\n",
            "Epoch 114/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3179 - accuracy: 0.9312 - val_loss: 2.8502 - val_accuracy: 0.5417\n",
            "Epoch 115/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3603 - accuracy: 0.9206 - val_loss: 2.5352 - val_accuracy: 0.5417\n",
            "Epoch 116/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3715 - accuracy: 0.9471 - val_loss: 2.5764 - val_accuracy: 0.5000\n",
            "Epoch 117/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3942 - accuracy: 0.9101 - val_loss: 2.5563 - val_accuracy: 0.5417\n",
            "Epoch 118/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.3786 - accuracy: 0.9206 - val_loss: 2.6141 - val_accuracy: 0.5833\n",
            "Epoch 119/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.4284 - accuracy: 0.9206 - val_loss: 2.6227 - val_accuracy: 0.5208\n",
            "Epoch 120/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.4160 - accuracy: 0.9101 - val_loss: 2.6005 - val_accuracy: 0.5208\n",
            "Epoch 121/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3611 - accuracy: 0.9524 - val_loss: 2.4183 - val_accuracy: 0.5417\n",
            "Epoch 122/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3699 - accuracy: 0.9206 - val_loss: 2.4450 - val_accuracy: 0.5417\n",
            "Epoch 123/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3863 - accuracy: 0.9101 - val_loss: 2.6957 - val_accuracy: 0.5208\n",
            "Epoch 124/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3955 - accuracy: 0.9153 - val_loss: 2.6509 - val_accuracy: 0.5000\n",
            "Epoch 125/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3984 - accuracy: 0.9153 - val_loss: 2.4640 - val_accuracy: 0.5417\n",
            "Epoch 126/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3755 - accuracy: 0.8995 - val_loss: 2.5660 - val_accuracy: 0.5625\n",
            "Epoch 127/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3255 - accuracy: 0.9524 - val_loss: 2.6027 - val_accuracy: 0.5625\n",
            "Epoch 128/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2803 - accuracy: 0.9788 - val_loss: 2.7018 - val_accuracy: 0.5625\n",
            "Epoch 129/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3092 - accuracy: 0.9524 - val_loss: 2.8825 - val_accuracy: 0.5208\n",
            "Epoch 130/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.3244 - accuracy: 0.9630 - val_loss: 2.9935 - val_accuracy: 0.5000\n",
            "Epoch 131/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.2978 - accuracy: 0.9630 - val_loss: 2.8636 - val_accuracy: 0.5000\n",
            "Epoch 132/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.3440 - accuracy: 0.9471 - val_loss: 2.8161 - val_accuracy: 0.5417\n",
            "Epoch 133/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3244 - accuracy: 0.9471 - val_loss: 2.7541 - val_accuracy: 0.5417\n",
            "Epoch 134/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2741 - accuracy: 0.9788 - val_loss: 2.6981 - val_accuracy: 0.5625\n",
            "Epoch 135/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2739 - accuracy: 0.9524 - val_loss: 2.6947 - val_accuracy: 0.5625\n",
            "Epoch 136/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3281 - accuracy: 0.9524 - val_loss: 2.7970 - val_accuracy: 0.5625\n",
            "Epoch 137/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.3082 - accuracy: 0.9365 - val_loss: 2.7609 - val_accuracy: 0.5833\n",
            "Epoch 138/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2903 - accuracy: 0.9630 - val_loss: 2.7486 - val_accuracy: 0.5417\n",
            "Epoch 139/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.2822 - accuracy: 0.9683 - val_loss: 3.0282 - val_accuracy: 0.5208\n",
            "Epoch 140/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3534 - accuracy: 0.9418 - val_loss: 2.6887 - val_accuracy: 0.5208\n",
            "Epoch 141/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.3000 - accuracy: 0.9471 - val_loss: 2.6058 - val_accuracy: 0.5417\n",
            "Epoch 142/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2963 - accuracy: 0.9312 - val_loss: 2.6943 - val_accuracy: 0.5417\n",
            "Epoch 143/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2532 - accuracy: 0.9735 - val_loss: 2.8176 - val_accuracy: 0.5625\n",
            "Epoch 144/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2621 - accuracy: 0.9577 - val_loss: 2.9395 - val_accuracy: 0.5417\n",
            "Epoch 145/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2447 - accuracy: 0.9735 - val_loss: 2.8464 - val_accuracy: 0.5417\n",
            "Epoch 146/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2795 - accuracy: 0.9471 - val_loss: 2.8882 - val_accuracy: 0.5417\n",
            "Epoch 147/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2736 - accuracy: 0.9577 - val_loss: 2.9608 - val_accuracy: 0.5417\n",
            "Epoch 148/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.2499 - accuracy: 0.9735 - val_loss: 2.9429 - val_accuracy: 0.5208\n",
            "Epoch 149/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2544 - accuracy: 0.9630 - val_loss: 2.8197 - val_accuracy: 0.5208\n",
            "Epoch 150/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2623 - accuracy: 0.9524 - val_loss: 2.5844 - val_accuracy: 0.5417\n",
            "Epoch 151/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2781 - accuracy: 0.9524 - val_loss: 2.5646 - val_accuracy: 0.5625\n",
            "Epoch 152/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.2350 - accuracy: 0.9630 - val_loss: 2.6896 - val_accuracy: 0.5208\n",
            "Epoch 153/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2894 - accuracy: 0.9524 - val_loss: 2.5020 - val_accuracy: 0.5208\n",
            "Epoch 154/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2309 - accuracy: 0.9788 - val_loss: 2.2918 - val_accuracy: 0.5417\n",
            "Epoch 155/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3205 - accuracy: 0.9312 - val_loss: 2.2892 - val_accuracy: 0.5417\n",
            "Epoch 156/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2616 - accuracy: 0.9630 - val_loss: 2.5990 - val_accuracy: 0.5208\n",
            "Epoch 157/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.2399 - accuracy: 0.9735 - val_loss: 2.5691 - val_accuracy: 0.5417\n",
            "Epoch 158/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2759 - accuracy: 0.9471 - val_loss: 2.6215 - val_accuracy: 0.5417\n",
            "Epoch 159/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.3103 - accuracy: 0.9418 - val_loss: 2.8293 - val_accuracy: 0.5625\n",
            "Epoch 160/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.2677 - accuracy: 0.9630 - val_loss: 2.7096 - val_accuracy: 0.5833\n",
            "Epoch 161/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2438 - accuracy: 0.9735 - val_loss: 2.6798 - val_accuracy: 0.5833\n",
            "Epoch 162/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2577 - accuracy: 0.9471 - val_loss: 2.8784 - val_accuracy: 0.6042\n",
            "Epoch 163/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2245 - accuracy: 0.9841 - val_loss: 2.8746 - val_accuracy: 0.5833\n",
            "Epoch 164/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2440 - accuracy: 0.9577 - val_loss: 2.9065 - val_accuracy: 0.5417\n",
            "Epoch 165/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2552 - accuracy: 0.9577 - val_loss: 2.9699 - val_accuracy: 0.5833\n",
            "Epoch 166/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.1956 - accuracy: 0.9894 - val_loss: 2.8687 - val_accuracy: 0.5625\n",
            "Epoch 167/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.1933 - accuracy: 0.9894 - val_loss: 2.9193 - val_accuracy: 0.5417\n",
            "Epoch 168/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.2633 - accuracy: 0.9577 - val_loss: 2.6523 - val_accuracy: 0.5625\n",
            "Epoch 169/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2377 - accuracy: 0.9577 - val_loss: 2.5465 - val_accuracy: 0.5833\n",
            "Epoch 170/500\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.2223 - accuracy: 0.9630 - val_loss: 2.4929 - val_accuracy: 0.5625\n",
            "Epoch 171/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2110 - accuracy: 0.9630 - val_loss: 2.6809 - val_accuracy: 0.5417\n",
            "Epoch 172/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2250 - accuracy: 0.9788 - val_loss: 2.5503 - val_accuracy: 0.5208\n",
            "Epoch 173/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2836 - accuracy: 0.9418 - val_loss: 2.5809 - val_accuracy: 0.5417\n",
            "Epoch 174/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2351 - accuracy: 0.9683 - val_loss: 2.6801 - val_accuracy: 0.5417\n",
            "Epoch 175/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2594 - accuracy: 0.9683 - val_loss: 2.5763 - val_accuracy: 0.5417\n",
            "Epoch 176/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1869 - accuracy: 0.9947 - val_loss: 2.4049 - val_accuracy: 0.6042\n",
            "Epoch 177/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2622 - accuracy: 0.9524 - val_loss: 2.4083 - val_accuracy: 0.6042\n",
            "Epoch 178/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2938 - accuracy: 0.9471 - val_loss: 2.7484 - val_accuracy: 0.5833\n",
            "Epoch 179/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2431 - accuracy: 0.9735 - val_loss: 2.8653 - val_accuracy: 0.5625\n",
            "Epoch 180/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2926 - accuracy: 0.9365 - val_loss: 2.6710 - val_accuracy: 0.6250\n",
            "Epoch 181/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2605 - accuracy: 0.9683 - val_loss: 2.7592 - val_accuracy: 0.6042\n",
            "Epoch 182/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2365 - accuracy: 0.9788 - val_loss: 2.7894 - val_accuracy: 0.5833\n",
            "Epoch 183/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2550 - accuracy: 0.9577 - val_loss: 2.6786 - val_accuracy: 0.6042\n",
            "Epoch 184/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.2206 - accuracy: 0.9788 - val_loss: 2.6107 - val_accuracy: 0.6042\n",
            "Epoch 185/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2630 - accuracy: 0.9577 - val_loss: 2.5895 - val_accuracy: 0.5833\n",
            "Epoch 186/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2496 - accuracy: 0.9577 - val_loss: 2.6581 - val_accuracy: 0.6042\n",
            "Epoch 187/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.2316 - accuracy: 0.9577 - val_loss: 2.6516 - val_accuracy: 0.5833\n",
            "Epoch 188/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2530 - accuracy: 0.9577 - val_loss: 2.6808 - val_accuracy: 0.5833\n",
            "Epoch 189/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1961 - accuracy: 0.9841 - val_loss: 2.7716 - val_accuracy: 0.5625\n",
            "Epoch 190/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2313 - accuracy: 0.9683 - val_loss: 2.7588 - val_accuracy: 0.6458\n",
            "Epoch 191/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.2324 - accuracy: 0.9683 - val_loss: 2.8603 - val_accuracy: 0.5833\n",
            "Epoch 192/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2461 - accuracy: 0.9683 - val_loss: 2.8283 - val_accuracy: 0.5833\n",
            "Epoch 193/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1985 - accuracy: 0.9788 - val_loss: 2.9889 - val_accuracy: 0.5625\n",
            "Epoch 194/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.2391 - accuracy: 0.9683 - val_loss: 3.0056 - val_accuracy: 0.5833\n",
            "Epoch 195/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2034 - accuracy: 0.9788 - val_loss: 2.7849 - val_accuracy: 0.5625\n",
            "Epoch 196/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2359 - accuracy: 0.9630 - val_loss: 2.6553 - val_accuracy: 0.6042\n",
            "Epoch 197/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2299 - accuracy: 0.9735 - val_loss: 2.5586 - val_accuracy: 0.6042\n",
            "Epoch 198/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2413 - accuracy: 0.9630 - val_loss: 2.5818 - val_accuracy: 0.5417\n",
            "Epoch 199/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2745 - accuracy: 0.9206 - val_loss: 2.8659 - val_accuracy: 0.5417\n",
            "Epoch 200/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2190 - accuracy: 0.9735 - val_loss: 2.9161 - val_accuracy: 0.5417\n",
            "Epoch 201/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2244 - accuracy: 0.9735 - val_loss: 2.8811 - val_accuracy: 0.5417\n",
            "Epoch 202/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2312 - accuracy: 0.9841 - val_loss: 2.8013 - val_accuracy: 0.5833\n",
            "Epoch 203/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1794 - accuracy: 0.9894 - val_loss: 2.7686 - val_accuracy: 0.5625\n",
            "Epoch 204/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2444 - accuracy: 0.9630 - val_loss: 2.8459 - val_accuracy: 0.5833\n",
            "Epoch 205/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2059 - accuracy: 0.9947 - val_loss: 2.9065 - val_accuracy: 0.5833\n",
            "Epoch 206/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1818 - accuracy: 0.9630 - val_loss: 2.8605 - val_accuracy: 0.5833\n",
            "Epoch 207/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1824 - accuracy: 0.9788 - val_loss: 2.8380 - val_accuracy: 0.5833\n",
            "Epoch 208/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1935 - accuracy: 0.9841 - val_loss: 2.8502 - val_accuracy: 0.5833\n",
            "Epoch 209/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2191 - accuracy: 0.9471 - val_loss: 2.9996 - val_accuracy: 0.5833\n",
            "Epoch 210/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.2339 - accuracy: 0.9683 - val_loss: 2.8531 - val_accuracy: 0.5833\n",
            "Epoch 211/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2048 - accuracy: 0.9683 - val_loss: 2.6550 - val_accuracy: 0.6042\n",
            "Epoch 212/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.2009 - accuracy: 0.9788 - val_loss: 2.7836 - val_accuracy: 0.6250\n",
            "Epoch 213/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2227 - accuracy: 0.9630 - val_loss: 2.7353 - val_accuracy: 0.5833\n",
            "Epoch 214/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2274 - accuracy: 0.9524 - val_loss: 2.7671 - val_accuracy: 0.5833\n",
            "Epoch 215/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2227 - accuracy: 0.9683 - val_loss: 2.5533 - val_accuracy: 0.6458\n",
            "Epoch 216/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2018 - accuracy: 0.9683 - val_loss: 2.5054 - val_accuracy: 0.6042\n",
            "Epoch 217/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2298 - accuracy: 0.9630 - val_loss: 2.6713 - val_accuracy: 0.5833\n",
            "Epoch 218/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2211 - accuracy: 0.9683 - val_loss: 2.8279 - val_accuracy: 0.5417\n",
            "Epoch 219/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2065 - accuracy: 0.9735 - val_loss: 2.8820 - val_accuracy: 0.6250\n",
            "Epoch 220/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2333 - accuracy: 0.9630 - val_loss: 2.8097 - val_accuracy: 0.6250\n",
            "Epoch 221/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2204 - accuracy: 0.9735 - val_loss: 2.8719 - val_accuracy: 0.6042\n",
            "Epoch 222/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2176 - accuracy: 0.9894 - val_loss: 2.8515 - val_accuracy: 0.6042\n",
            "Epoch 223/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2213 - accuracy: 0.9735 - val_loss: 2.8589 - val_accuracy: 0.5417\n",
            "Epoch 224/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2174 - accuracy: 0.9577 - val_loss: 3.1226 - val_accuracy: 0.5417\n",
            "Epoch 225/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2098 - accuracy: 0.9788 - val_loss: 3.0934 - val_accuracy: 0.5833\n",
            "Epoch 226/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2447 - accuracy: 0.9577 - val_loss: 3.0831 - val_accuracy: 0.5625\n",
            "Epoch 227/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2657 - accuracy: 0.9418 - val_loss: 3.1130 - val_accuracy: 0.6042\n",
            "Epoch 228/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2832 - accuracy: 0.9312 - val_loss: 3.2041 - val_accuracy: 0.5625\n",
            "Epoch 229/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2616 - accuracy: 0.9524 - val_loss: 3.1317 - val_accuracy: 0.5417\n",
            "Epoch 230/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2710 - accuracy: 0.9577 - val_loss: 3.0049 - val_accuracy: 0.5625\n",
            "Epoch 231/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2185 - accuracy: 0.9788 - val_loss: 3.5215 - val_accuracy: 0.5417\n",
            "Epoch 232/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.3222 - accuracy: 0.9312 - val_loss: 3.0421 - val_accuracy: 0.5833\n",
            "Epoch 233/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.3014 - accuracy: 0.9365 - val_loss: 2.7227 - val_accuracy: 0.6042\n",
            "Epoch 234/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.2602 - accuracy: 0.9577 - val_loss: 2.7724 - val_accuracy: 0.5833\n",
            "Epoch 235/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2581 - accuracy: 0.9471 - val_loss: 2.6417 - val_accuracy: 0.6250\n",
            "Epoch 236/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.2547 - accuracy: 0.9630 - val_loss: 3.0878 - val_accuracy: 0.5833\n",
            "Epoch 237/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.3052 - accuracy: 0.9471 - val_loss: 3.4077 - val_accuracy: 0.5208\n",
            "Epoch 238/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2416 - accuracy: 0.9683 - val_loss: 3.3119 - val_accuracy: 0.5417\n",
            "Epoch 239/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2344 - accuracy: 0.9630 - val_loss: 2.9360 - val_accuracy: 0.5833\n",
            "Epoch 240/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2924 - accuracy: 0.9365 - val_loss: 3.1014 - val_accuracy: 0.5625\n",
            "Epoch 241/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2395 - accuracy: 0.9630 - val_loss: 3.1458 - val_accuracy: 0.5417\n",
            "Epoch 242/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2876 - accuracy: 0.9471 - val_loss: 3.0623 - val_accuracy: 0.5417\n",
            "Epoch 243/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2978 - accuracy: 0.9471 - val_loss: 2.9538 - val_accuracy: 0.5625\n",
            "Epoch 244/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2313 - accuracy: 0.9788 - val_loss: 3.1545 - val_accuracy: 0.5625\n",
            "Epoch 245/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.2990 - accuracy: 0.9365 - val_loss: 3.0651 - val_accuracy: 0.5833\n",
            "Epoch 246/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2366 - accuracy: 0.9683 - val_loss: 3.1043 - val_accuracy: 0.5833\n",
            "Epoch 247/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1952 - accuracy: 0.9894 - val_loss: 2.9775 - val_accuracy: 0.6042\n",
            "Epoch 248/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1887 - accuracy: 0.9894 - val_loss: 2.7398 - val_accuracy: 0.6042\n",
            "Epoch 249/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.2301 - accuracy: 0.9683 - val_loss: 2.5679 - val_accuracy: 0.5833\n",
            "Epoch 250/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.1731 - accuracy: 0.9894 - val_loss: 2.8057 - val_accuracy: 0.5417\n",
            "Epoch 251/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2591 - accuracy: 0.9630 - val_loss: 3.0465 - val_accuracy: 0.5625\n",
            "Epoch 252/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2177 - accuracy: 0.9630 - val_loss: 2.7925 - val_accuracy: 0.6042\n",
            "Epoch 253/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1785 - accuracy: 0.9841 - val_loss: 2.8289 - val_accuracy: 0.6042\n",
            "Epoch 254/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2493 - accuracy: 0.9577 - val_loss: 2.6701 - val_accuracy: 0.5833\n",
            "Epoch 255/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2442 - accuracy: 0.9630 - val_loss: 2.8771 - val_accuracy: 0.6042\n",
            "Epoch 256/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2142 - accuracy: 0.9683 - val_loss: 2.9869 - val_accuracy: 0.5833\n",
            "Epoch 257/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2389 - accuracy: 0.9577 - val_loss: 2.7903 - val_accuracy: 0.6250\n",
            "Epoch 258/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2476 - accuracy: 0.9577 - val_loss: 2.9513 - val_accuracy: 0.5833\n",
            "Epoch 259/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2222 - accuracy: 0.9577 - val_loss: 2.5292 - val_accuracy: 0.6667\n",
            "Epoch 260/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2541 - accuracy: 0.9524 - val_loss: 2.6393 - val_accuracy: 0.6458\n",
            "Epoch 261/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1902 - accuracy: 0.9788 - val_loss: 2.2664 - val_accuracy: 0.6875\n",
            "Epoch 262/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2125 - accuracy: 0.9735 - val_loss: 2.2178 - val_accuracy: 0.6875\n",
            "Epoch 263/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2474 - accuracy: 0.9418 - val_loss: 2.3199 - val_accuracy: 0.6458\n",
            "Epoch 264/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2381 - accuracy: 0.9577 - val_loss: 2.7938 - val_accuracy: 0.5833\n",
            "Epoch 265/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2278 - accuracy: 0.9524 - val_loss: 2.9804 - val_accuracy: 0.5625\n",
            "Epoch 266/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2426 - accuracy: 0.9524 - val_loss: 3.0834 - val_accuracy: 0.5417\n",
            "Epoch 267/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.2035 - accuracy: 0.9788 - val_loss: 2.9335 - val_accuracy: 0.5625\n",
            "Epoch 268/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1646 - accuracy: 0.9894 - val_loss: 2.9510 - val_accuracy: 0.5625\n",
            "Epoch 269/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2055 - accuracy: 0.9735 - val_loss: 2.8530 - val_accuracy: 0.6250\n",
            "Epoch 270/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2243 - accuracy: 0.9577 - val_loss: 2.8868 - val_accuracy: 0.6042\n",
            "Epoch 271/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2692 - accuracy: 0.9471 - val_loss: 2.8819 - val_accuracy: 0.5833\n",
            "Epoch 272/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1821 - accuracy: 0.9841 - val_loss: 2.8202 - val_accuracy: 0.6042\n",
            "Epoch 273/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2454 - accuracy: 0.9630 - val_loss: 2.8675 - val_accuracy: 0.5417\n",
            "Epoch 274/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2284 - accuracy: 0.9524 - val_loss: 2.7081 - val_accuracy: 0.5417\n",
            "Epoch 275/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2177 - accuracy: 0.9630 - val_loss: 2.7429 - val_accuracy: 0.5833\n",
            "Epoch 276/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.1798 - accuracy: 0.9841 - val_loss: 2.6531 - val_accuracy: 0.5833\n",
            "Epoch 277/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1828 - accuracy: 0.9841 - val_loss: 2.5603 - val_accuracy: 0.6042\n",
            "Epoch 278/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2376 - accuracy: 0.9577 - val_loss: 2.5398 - val_accuracy: 0.6667\n",
            "Epoch 279/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2009 - accuracy: 0.9788 - val_loss: 2.6079 - val_accuracy: 0.6250\n",
            "Epoch 280/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2298 - accuracy: 0.9683 - val_loss: 2.4894 - val_accuracy: 0.6250\n",
            "Epoch 281/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2157 - accuracy: 0.9735 - val_loss: 2.4073 - val_accuracy: 0.6667\n",
            "Epoch 282/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.2405 - accuracy: 0.9630 - val_loss: 2.5145 - val_accuracy: 0.6667\n",
            "Epoch 283/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1959 - accuracy: 0.9735 - val_loss: 2.6062 - val_accuracy: 0.6042\n",
            "Epoch 284/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1981 - accuracy: 0.9735 - val_loss: 2.5320 - val_accuracy: 0.5833\n",
            "Epoch 285/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1992 - accuracy: 0.9735 - val_loss: 2.6149 - val_accuracy: 0.6042\n",
            "Epoch 286/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1943 - accuracy: 0.9683 - val_loss: 2.6866 - val_accuracy: 0.5833\n",
            "Epoch 287/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1597 - accuracy: 0.9894 - val_loss: 2.6316 - val_accuracy: 0.5833\n",
            "Epoch 288/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2248 - accuracy: 0.9683 - val_loss: 2.7300 - val_accuracy: 0.5833\n",
            "Epoch 289/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1848 - accuracy: 0.9788 - val_loss: 2.8370 - val_accuracy: 0.5833\n",
            "Epoch 290/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1717 - accuracy: 0.9894 - val_loss: 2.7023 - val_accuracy: 0.6042\n",
            "Epoch 291/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1855 - accuracy: 0.9683 - val_loss: 2.6700 - val_accuracy: 0.6042\n",
            "Epoch 292/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2049 - accuracy: 0.9735 - val_loss: 2.6023 - val_accuracy: 0.6250\n",
            "Epoch 293/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1848 - accuracy: 0.9735 - val_loss: 2.3718 - val_accuracy: 0.6667\n",
            "Epoch 294/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1844 - accuracy: 0.9841 - val_loss: 2.5336 - val_accuracy: 0.6458\n",
            "Epoch 295/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2226 - accuracy: 0.9577 - val_loss: 2.5604 - val_accuracy: 0.6458\n",
            "Epoch 296/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1831 - accuracy: 0.9735 - val_loss: 2.6539 - val_accuracy: 0.6458\n",
            "Epoch 297/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1892 - accuracy: 0.9630 - val_loss: 2.7093 - val_accuracy: 0.6250\n",
            "Epoch 298/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.2007 - accuracy: 0.9577 - val_loss: 2.7142 - val_accuracy: 0.6042\n",
            "Epoch 299/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2099 - accuracy: 0.9577 - val_loss: 2.8264 - val_accuracy: 0.6250\n",
            "Epoch 300/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2166 - accuracy: 0.9577 - val_loss: 2.6484 - val_accuracy: 0.6458\n",
            "Epoch 301/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1981 - accuracy: 0.9577 - val_loss: 2.6385 - val_accuracy: 0.6458\n",
            "Epoch 302/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1673 - accuracy: 0.9735 - val_loss: 2.6838 - val_accuracy: 0.6458\n",
            "Epoch 303/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1890 - accuracy: 0.9683 - val_loss: 2.6685 - val_accuracy: 0.6250\n",
            "Epoch 304/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2069 - accuracy: 0.9683 - val_loss: 2.4540 - val_accuracy: 0.6458\n",
            "Epoch 305/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2071 - accuracy: 0.9524 - val_loss: 2.7716 - val_accuracy: 0.6458\n",
            "Epoch 306/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1762 - accuracy: 0.9735 - val_loss: 3.0141 - val_accuracy: 0.6042\n",
            "Epoch 307/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1870 - accuracy: 0.9735 - val_loss: 3.1976 - val_accuracy: 0.5417\n",
            "Epoch 308/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2452 - accuracy: 0.9577 - val_loss: 2.7804 - val_accuracy: 0.5833\n",
            "Epoch 309/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1914 - accuracy: 0.9894 - val_loss: 2.4161 - val_accuracy: 0.6667\n",
            "Epoch 310/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2243 - accuracy: 0.9577 - val_loss: 2.2879 - val_accuracy: 0.6042\n",
            "Epoch 311/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1985 - accuracy: 0.9683 - val_loss: 2.2097 - val_accuracy: 0.6667\n",
            "Epoch 312/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.2395 - accuracy: 0.9418 - val_loss: 2.3248 - val_accuracy: 0.6042\n",
            "Epoch 313/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1751 - accuracy: 0.9683 - val_loss: 2.7653 - val_accuracy: 0.6042\n",
            "Epoch 314/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2293 - accuracy: 0.9524 - val_loss: 2.8833 - val_accuracy: 0.6042\n",
            "Epoch 315/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2127 - accuracy: 0.9630 - val_loss: 3.0957 - val_accuracy: 0.5833\n",
            "Epoch 316/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1962 - accuracy: 0.9735 - val_loss: 3.2957 - val_accuracy: 0.5833\n",
            "Epoch 317/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1820 - accuracy: 0.9735 - val_loss: 3.2548 - val_accuracy: 0.5625\n",
            "Epoch 318/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1978 - accuracy: 0.9841 - val_loss: 3.0205 - val_accuracy: 0.5833\n",
            "Epoch 319/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3644 - accuracy: 0.9471 - val_loss: 3.5933 - val_accuracy: 0.5000\n",
            "Epoch 320/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.4616 - accuracy: 0.8783 - val_loss: 3.0314 - val_accuracy: 0.5833\n",
            "Epoch 321/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3917 - accuracy: 0.8889 - val_loss: 2.7733 - val_accuracy: 0.5625\n",
            "Epoch 322/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.4449 - accuracy: 0.9101 - val_loss: 2.9286 - val_accuracy: 0.6250\n",
            "Epoch 323/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3718 - accuracy: 0.9101 - val_loss: 2.8963 - val_accuracy: 0.5625\n",
            "Epoch 324/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2522 - accuracy: 0.9630 - val_loss: 2.8431 - val_accuracy: 0.5417\n",
            "Epoch 325/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.3419 - accuracy: 0.9153 - val_loss: 2.7829 - val_accuracy: 0.6458\n",
            "Epoch 326/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.2378 - accuracy: 0.9735 - val_loss: 2.7529 - val_accuracy: 0.6458\n",
            "Epoch 327/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2352 - accuracy: 0.9683 - val_loss: 2.7684 - val_accuracy: 0.6875\n",
            "Epoch 328/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2868 - accuracy: 0.9418 - val_loss: 2.9107 - val_accuracy: 0.6250\n",
            "Epoch 329/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2811 - accuracy: 0.9471 - val_loss: 2.8642 - val_accuracy: 0.6042\n",
            "Epoch 330/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2471 - accuracy: 0.9630 - val_loss: 2.8690 - val_accuracy: 0.5625\n",
            "Epoch 331/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2497 - accuracy: 0.9471 - val_loss: 2.8132 - val_accuracy: 0.6667\n",
            "Epoch 332/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2646 - accuracy: 0.9524 - val_loss: 3.0237 - val_accuracy: 0.6042\n",
            "Epoch 333/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2353 - accuracy: 0.9735 - val_loss: 3.0336 - val_accuracy: 0.6042\n",
            "Epoch 334/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2409 - accuracy: 0.9630 - val_loss: 2.8818 - val_accuracy: 0.5833\n",
            "Epoch 335/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2281 - accuracy: 0.9735 - val_loss: 2.8953 - val_accuracy: 0.6042\n",
            "Epoch 336/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2043 - accuracy: 0.9788 - val_loss: 3.0226 - val_accuracy: 0.5833\n",
            "Epoch 337/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2480 - accuracy: 0.9630 - val_loss: 2.7949 - val_accuracy: 0.6042\n",
            "Epoch 338/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2054 - accuracy: 0.9735 - val_loss: 2.7532 - val_accuracy: 0.6458\n",
            "Epoch 339/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2103 - accuracy: 0.9683 - val_loss: 2.8347 - val_accuracy: 0.5417\n",
            "Epoch 340/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1835 - accuracy: 0.9894 - val_loss: 2.7812 - val_accuracy: 0.5208\n",
            "Epoch 341/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1868 - accuracy: 0.9894 - val_loss: 2.7412 - val_accuracy: 0.5417\n",
            "Epoch 342/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.1676 - accuracy: 0.9894 - val_loss: 2.8193 - val_accuracy: 0.5625\n",
            "Epoch 343/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1649 - accuracy: 0.9894 - val_loss: 2.8586 - val_accuracy: 0.5833\n",
            "Epoch 344/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1896 - accuracy: 0.9788 - val_loss: 2.8641 - val_accuracy: 0.5625\n",
            "Epoch 345/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2006 - accuracy: 0.9788 - val_loss: 2.8878 - val_accuracy: 0.5625\n",
            "Epoch 346/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1690 - accuracy: 0.9841 - val_loss: 2.9858 - val_accuracy: 0.5625\n",
            "Epoch 347/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2151 - accuracy: 0.9418 - val_loss: 2.8351 - val_accuracy: 0.5833\n",
            "Epoch 348/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1581 - accuracy: 0.9841 - val_loss: 2.8770 - val_accuracy: 0.5625\n",
            "Epoch 349/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1564 - accuracy: 0.9841 - val_loss: 2.7976 - val_accuracy: 0.6458\n",
            "Epoch 350/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1984 - accuracy: 0.9735 - val_loss: 2.7930 - val_accuracy: 0.6458\n",
            "Epoch 351/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1393 - accuracy: 0.9894 - val_loss: 2.8506 - val_accuracy: 0.6250\n",
            "Epoch 352/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1837 - accuracy: 0.9577 - val_loss: 2.7326 - val_accuracy: 0.5625\n",
            "Epoch 353/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1855 - accuracy: 0.9630 - val_loss: 2.7563 - val_accuracy: 0.5625\n",
            "Epoch 354/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2020 - accuracy: 0.9577 - val_loss: 2.6727 - val_accuracy: 0.5833\n",
            "Epoch 355/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1811 - accuracy: 0.9683 - val_loss: 2.5035 - val_accuracy: 0.5833\n",
            "Epoch 356/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 0.1534 - accuracy: 0.9894 - val_loss: 2.5029 - val_accuracy: 0.6042\n",
            "Epoch 357/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2227 - accuracy: 0.9577 - val_loss: 2.8189 - val_accuracy: 0.5833\n",
            "Epoch 358/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.1970 - accuracy: 0.9577 - val_loss: 3.1415 - val_accuracy: 0.5833\n",
            "Epoch 359/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1874 - accuracy: 0.9841 - val_loss: 3.1053 - val_accuracy: 0.6042\n",
            "Epoch 360/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1757 - accuracy: 0.9894 - val_loss: 3.0776 - val_accuracy: 0.5833\n",
            "Epoch 361/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1953 - accuracy: 0.9683 - val_loss: 2.9221 - val_accuracy: 0.5625\n",
            "Epoch 362/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1928 - accuracy: 0.9683 - val_loss: 2.7240 - val_accuracy: 0.5833\n",
            "Epoch 363/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1855 - accuracy: 0.9735 - val_loss: 2.3947 - val_accuracy: 0.6042\n",
            "Epoch 364/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1615 - accuracy: 0.9894 - val_loss: 2.2515 - val_accuracy: 0.6250\n",
            "Epoch 365/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1620 - accuracy: 0.9894 - val_loss: 2.2287 - val_accuracy: 0.6458\n",
            "Epoch 366/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1904 - accuracy: 0.9630 - val_loss: 2.4514 - val_accuracy: 0.6458\n",
            "Epoch 367/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1678 - accuracy: 0.9894 - val_loss: 2.4811 - val_accuracy: 0.6458\n",
            "Epoch 368/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1803 - accuracy: 0.9735 - val_loss: 2.4533 - val_accuracy: 0.6458\n",
            "Epoch 369/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.2020 - accuracy: 0.9630 - val_loss: 2.4968 - val_accuracy: 0.6042\n",
            "Epoch 370/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.1412 - accuracy: 0.9841 - val_loss: 2.5613 - val_accuracy: 0.6042\n",
            "Epoch 371/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1925 - accuracy: 0.9735 - val_loss: 2.4394 - val_accuracy: 0.6458\n",
            "Epoch 372/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2027 - accuracy: 0.9577 - val_loss: 2.3877 - val_accuracy: 0.6250\n",
            "Epoch 373/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1617 - accuracy: 0.9841 - val_loss: 2.4341 - val_accuracy: 0.6667\n",
            "Epoch 374/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1859 - accuracy: 0.9683 - val_loss: 2.5227 - val_accuracy: 0.6458\n",
            "Epoch 375/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1825 - accuracy: 0.9735 - val_loss: 2.3365 - val_accuracy: 0.6667\n",
            "Epoch 376/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1856 - accuracy: 0.9735 - val_loss: 2.3203 - val_accuracy: 0.6667\n",
            "Epoch 377/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1429 - accuracy: 0.9894 - val_loss: 2.3889 - val_accuracy: 0.6458\n",
            "Epoch 378/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1364 - accuracy: 0.9947 - val_loss: 2.4652 - val_accuracy: 0.6250\n",
            "Epoch 379/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1901 - accuracy: 0.9630 - val_loss: 2.5769 - val_accuracy: 0.6042\n",
            "Epoch 380/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1810 - accuracy: 0.9683 - val_loss: 2.8782 - val_accuracy: 0.5625\n",
            "Epoch 381/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1751 - accuracy: 0.9735 - val_loss: 2.8695 - val_accuracy: 0.5417\n",
            "Epoch 382/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1745 - accuracy: 0.9788 - val_loss: 2.9069 - val_accuracy: 0.5625\n",
            "Epoch 383/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.1822 - accuracy: 0.9788 - val_loss: 2.7721 - val_accuracy: 0.5625\n",
            "Epoch 384/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2117 - accuracy: 0.9630 - val_loss: 2.8580 - val_accuracy: 0.5833\n",
            "Epoch 385/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1684 - accuracy: 0.9894 - val_loss: 2.8675 - val_accuracy: 0.5625\n",
            "Epoch 386/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2090 - accuracy: 0.9524 - val_loss: 2.8519 - val_accuracy: 0.5625\n",
            "Epoch 387/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1886 - accuracy: 0.9735 - val_loss: 2.9116 - val_accuracy: 0.5833\n",
            "Epoch 388/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2114 - accuracy: 0.9524 - val_loss: 2.7264 - val_accuracy: 0.5833\n",
            "Epoch 389/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1878 - accuracy: 0.9630 - val_loss: 2.7413 - val_accuracy: 0.5833\n",
            "Epoch 390/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1511 - accuracy: 0.9894 - val_loss: 2.7076 - val_accuracy: 0.6042\n",
            "Epoch 391/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1751 - accuracy: 0.9735 - val_loss: 2.5282 - val_accuracy: 0.6042\n",
            "Epoch 392/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1895 - accuracy: 0.9683 - val_loss: 2.5883 - val_accuracy: 0.5833\n",
            "Epoch 393/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1873 - accuracy: 0.9683 - val_loss: 2.6538 - val_accuracy: 0.6250\n",
            "Epoch 394/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1597 - accuracy: 0.9841 - val_loss: 2.6487 - val_accuracy: 0.6667\n",
            "Epoch 395/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1567 - accuracy: 0.9735 - val_loss: 2.8272 - val_accuracy: 0.6667\n",
            "Epoch 396/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.2420 - accuracy: 0.9524 - val_loss: 3.0301 - val_accuracy: 0.6458\n",
            "Epoch 397/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1690 - accuracy: 0.9788 - val_loss: 3.0196 - val_accuracy: 0.5417\n",
            "Epoch 398/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1544 - accuracy: 0.9788 - val_loss: 2.9778 - val_accuracy: 0.5208\n",
            "Epoch 399/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1679 - accuracy: 0.9735 - val_loss: 2.8559 - val_accuracy: 0.5000\n",
            "Epoch 400/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1668 - accuracy: 0.9630 - val_loss: 2.7842 - val_accuracy: 0.5000\n",
            "Epoch 401/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1732 - accuracy: 0.9788 - val_loss: 2.6576 - val_accuracy: 0.5833\n",
            "Epoch 402/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1711 - accuracy: 0.9683 - val_loss: 2.5785 - val_accuracy: 0.6250\n",
            "Epoch 403/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1694 - accuracy: 0.9683 - val_loss: 2.5900 - val_accuracy: 0.6458\n",
            "Epoch 404/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1531 - accuracy: 0.9788 - val_loss: 2.5988 - val_accuracy: 0.6458\n",
            "Epoch 405/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1920 - accuracy: 0.9735 - val_loss: 2.6238 - val_accuracy: 0.6250\n",
            "Epoch 406/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1546 - accuracy: 0.9735 - val_loss: 2.6902 - val_accuracy: 0.6250\n",
            "Epoch 407/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1410 - accuracy: 0.9894 - val_loss: 2.6955 - val_accuracy: 0.6042\n",
            "Epoch 408/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.1865 - accuracy: 0.9577 - val_loss: 2.6217 - val_accuracy: 0.5833\n",
            "Epoch 409/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1420 - accuracy: 1.0000 - val_loss: 2.7072 - val_accuracy: 0.5833\n",
            "Epoch 410/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1954 - accuracy: 0.9735 - val_loss: 2.5405 - val_accuracy: 0.5833\n",
            "Epoch 411/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1832 - accuracy: 0.9630 - val_loss: 2.3459 - val_accuracy: 0.6458\n",
            "Epoch 412/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2097 - accuracy: 0.9630 - val_loss: 2.3103 - val_accuracy: 0.6667\n",
            "Epoch 413/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1661 - accuracy: 0.9841 - val_loss: 2.4163 - val_accuracy: 0.6458\n",
            "Epoch 414/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1653 - accuracy: 0.9894 - val_loss: 2.4463 - val_accuracy: 0.6667\n",
            "Epoch 415/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1545 - accuracy: 0.9841 - val_loss: 2.5532 - val_accuracy: 0.7083\n",
            "Epoch 416/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1931 - accuracy: 0.9630 - val_loss: 2.4958 - val_accuracy: 0.6875\n",
            "Epoch 417/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1770 - accuracy: 0.9735 - val_loss: 2.5691 - val_accuracy: 0.6250\n",
            "Epoch 418/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1795 - accuracy: 0.9788 - val_loss: 2.7556 - val_accuracy: 0.5833\n",
            "Epoch 419/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2199 - accuracy: 0.9365 - val_loss: 3.3054 - val_accuracy: 0.6042\n",
            "Epoch 420/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.2242 - accuracy: 0.9577 - val_loss: 3.5119 - val_accuracy: 0.6250\n",
            "Epoch 421/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2140 - accuracy: 0.9735 - val_loss: 3.3410 - val_accuracy: 0.6250\n",
            "Epoch 422/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2216 - accuracy: 0.9683 - val_loss: 3.0165 - val_accuracy: 0.6042\n",
            "Epoch 423/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1959 - accuracy: 0.9683 - val_loss: 3.0518 - val_accuracy: 0.5833\n",
            "Epoch 424/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2172 - accuracy: 0.9788 - val_loss: 3.0184 - val_accuracy: 0.6250\n",
            "Epoch 425/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1869 - accuracy: 0.9788 - val_loss: 2.8805 - val_accuracy: 0.6250\n",
            "Epoch 426/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1839 - accuracy: 0.9735 - val_loss: 2.7293 - val_accuracy: 0.6458\n",
            "Epoch 427/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.2687 - accuracy: 0.9471 - val_loss: 2.4611 - val_accuracy: 0.6458\n",
            "Epoch 428/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1966 - accuracy: 0.9683 - val_loss: 2.9724 - val_accuracy: 0.5833\n",
            "Epoch 429/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2848 - accuracy: 0.9259 - val_loss: 3.1342 - val_accuracy: 0.6042\n",
            "Epoch 430/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2283 - accuracy: 0.9577 - val_loss: 3.1883 - val_accuracy: 0.5625\n",
            "Epoch 431/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2493 - accuracy: 0.9577 - val_loss: 3.1432 - val_accuracy: 0.5833\n",
            "Epoch 432/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.2286 - accuracy: 0.9471 - val_loss: 3.3628 - val_accuracy: 0.5625\n",
            "Epoch 433/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2671 - accuracy: 0.9524 - val_loss: 3.3418 - val_accuracy: 0.6042\n",
            "Epoch 434/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.2470 - accuracy: 0.9683 - val_loss: 3.3685 - val_accuracy: 0.6250\n",
            "Epoch 435/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2341 - accuracy: 0.9471 - val_loss: 3.3107 - val_accuracy: 0.6042\n",
            "Epoch 436/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2285 - accuracy: 0.9630 - val_loss: 3.2991 - val_accuracy: 0.6042\n",
            "Epoch 437/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2687 - accuracy: 0.9418 - val_loss: 2.8886 - val_accuracy: 0.6250\n",
            "Epoch 438/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1991 - accuracy: 0.9735 - val_loss: 2.9403 - val_accuracy: 0.5833\n",
            "Epoch 439/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2478 - accuracy: 0.9630 - val_loss: 2.7136 - val_accuracy: 0.5625\n",
            "Epoch 440/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2251 - accuracy: 0.9683 - val_loss: 2.6597 - val_accuracy: 0.6667\n",
            "Epoch 441/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2464 - accuracy: 0.9524 - val_loss: 2.7803 - val_accuracy: 0.6042\n",
            "Epoch 442/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2547 - accuracy: 0.9630 - val_loss: 2.7264 - val_accuracy: 0.6250\n",
            "Epoch 443/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.2601 - accuracy: 0.9365 - val_loss: 3.0194 - val_accuracy: 0.6042\n",
            "Epoch 444/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2251 - accuracy: 0.9630 - val_loss: 3.1767 - val_accuracy: 0.6458\n",
            "Epoch 445/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2636 - accuracy: 0.9524 - val_loss: 3.0015 - val_accuracy: 0.6250\n",
            "Epoch 446/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2287 - accuracy: 0.9735 - val_loss: 3.0894 - val_accuracy: 0.6042\n",
            "Epoch 447/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1860 - accuracy: 0.9894 - val_loss: 3.3284 - val_accuracy: 0.6042\n",
            "Epoch 448/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2085 - accuracy: 0.9735 - val_loss: 3.3676 - val_accuracy: 0.6250\n",
            "Epoch 449/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2250 - accuracy: 0.9630 - val_loss: 3.0677 - val_accuracy: 0.6250\n",
            "Epoch 450/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.2019 - accuracy: 0.9788 - val_loss: 2.9962 - val_accuracy: 0.6667\n",
            "Epoch 451/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2218 - accuracy: 0.9735 - val_loss: 2.7335 - val_accuracy: 0.6875\n",
            "Epoch 452/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2371 - accuracy: 0.9471 - val_loss: 2.6212 - val_accuracy: 0.6250\n",
            "Epoch 453/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1927 - accuracy: 0.9683 - val_loss: 2.6509 - val_accuracy: 0.6042\n",
            "Epoch 454/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2099 - accuracy: 0.9735 - val_loss: 2.6882 - val_accuracy: 0.6250\n",
            "Epoch 455/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.2001 - accuracy: 0.9630 - val_loss: 2.6981 - val_accuracy: 0.6042\n",
            "Epoch 456/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1698 - accuracy: 0.9841 - val_loss: 2.6456 - val_accuracy: 0.6250\n",
            "Epoch 457/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1794 - accuracy: 0.9841 - val_loss: 2.8333 - val_accuracy: 0.6042\n",
            "Epoch 458/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2415 - accuracy: 0.9577 - val_loss: 3.0834 - val_accuracy: 0.6250\n",
            "Epoch 459/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1887 - accuracy: 0.9630 - val_loss: 3.0713 - val_accuracy: 0.6458\n",
            "Epoch 460/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2009 - accuracy: 0.9735 - val_loss: 3.0807 - val_accuracy: 0.6458\n",
            "Epoch 461/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1659 - accuracy: 0.9894 - val_loss: 2.8154 - val_accuracy: 0.6042\n",
            "Epoch 462/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1858 - accuracy: 0.9788 - val_loss: 2.7245 - val_accuracy: 0.6250\n",
            "Epoch 463/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1737 - accuracy: 0.9841 - val_loss: 2.6364 - val_accuracy: 0.6458\n",
            "Epoch 464/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1946 - accuracy: 0.9683 - val_loss: 2.6471 - val_accuracy: 0.6458\n",
            "Epoch 465/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1657 - accuracy: 0.9841 - val_loss: 2.6041 - val_accuracy: 0.6458\n",
            "Epoch 466/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.1646 - accuracy: 0.9788 - val_loss: 2.6524 - val_accuracy: 0.6458\n",
            "Epoch 467/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1734 - accuracy: 0.9735 - val_loss: 2.7172 - val_accuracy: 0.5833\n",
            "Epoch 468/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1648 - accuracy: 0.9788 - val_loss: 2.7514 - val_accuracy: 0.6042\n",
            "Epoch 469/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1506 - accuracy: 0.9894 - val_loss: 2.7836 - val_accuracy: 0.6042\n",
            "Epoch 470/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1763 - accuracy: 0.9788 - val_loss: 2.8750 - val_accuracy: 0.6042\n",
            "Epoch 471/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1953 - accuracy: 0.9683 - val_loss: 2.8713 - val_accuracy: 0.5833\n",
            "Epoch 472/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.2109 - accuracy: 0.9788 - val_loss: 2.7094 - val_accuracy: 0.5833\n",
            "Epoch 473/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1469 - accuracy: 0.9947 - val_loss: 2.7632 - val_accuracy: 0.6458\n",
            "Epoch 474/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1673 - accuracy: 0.9683 - val_loss: 2.7956 - val_accuracy: 0.6458\n",
            "Epoch 475/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1712 - accuracy: 0.9735 - val_loss: 2.5512 - val_accuracy: 0.6667\n",
            "Epoch 476/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1586 - accuracy: 0.9735 - val_loss: 2.4641 - val_accuracy: 0.6458\n",
            "Epoch 477/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1872 - accuracy: 0.9735 - val_loss: 2.5855 - val_accuracy: 0.6458\n",
            "Epoch 478/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1764 - accuracy: 0.9683 - val_loss: 2.9052 - val_accuracy: 0.6250\n",
            "Epoch 479/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1711 - accuracy: 0.9788 - val_loss: 2.9426 - val_accuracy: 0.6250\n",
            "Epoch 480/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1901 - accuracy: 0.9683 - val_loss: 2.6225 - val_accuracy: 0.6667\n",
            "Epoch 481/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.2310 - accuracy: 0.9630 - val_loss: 2.7337 - val_accuracy: 0.6667\n",
            "Epoch 482/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1667 - accuracy: 0.9735 - val_loss: 2.7958 - val_accuracy: 0.6875\n",
            "Epoch 483/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1587 - accuracy: 0.9788 - val_loss: 2.8138 - val_accuracy: 0.6875\n",
            "Epoch 484/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1720 - accuracy: 0.9735 - val_loss: 2.7117 - val_accuracy: 0.6458\n",
            "Epoch 485/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1719 - accuracy: 0.9841 - val_loss: 2.6305 - val_accuracy: 0.6458\n",
            "Epoch 486/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1795 - accuracy: 0.9788 - val_loss: 2.4755 - val_accuracy: 0.6667\n",
            "Epoch 487/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1557 - accuracy: 0.9894 - val_loss: 2.5386 - val_accuracy: 0.6667\n",
            "Epoch 488/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1437 - accuracy: 0.9841 - val_loss: 2.6594 - val_accuracy: 0.6667\n",
            "Epoch 489/500\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1910 - accuracy: 0.9630 - val_loss: 2.8181 - val_accuracy: 0.6250\n",
            "Epoch 490/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1526 - accuracy: 0.9841 - val_loss: 3.0194 - val_accuracy: 0.6042\n",
            "Epoch 491/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1327 - accuracy: 0.9947 - val_loss: 3.0741 - val_accuracy: 0.6042\n",
            "Epoch 492/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1456 - accuracy: 0.9894 - val_loss: 3.0112 - val_accuracy: 0.5833\n",
            "Epoch 493/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1529 - accuracy: 0.9841 - val_loss: 2.9899 - val_accuracy: 0.5833\n",
            "Epoch 494/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1461 - accuracy: 0.9894 - val_loss: 2.9665 - val_accuracy: 0.6042\n",
            "Epoch 495/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1702 - accuracy: 0.9683 - val_loss: 2.8428 - val_accuracy: 0.6042\n",
            "Epoch 496/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1509 - accuracy: 0.9841 - val_loss: 2.7244 - val_accuracy: 0.6042\n",
            "Epoch 497/500\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1710 - accuracy: 0.9735 - val_loss: 2.6097 - val_accuracy: 0.7083\n",
            "Epoch 498/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1432 - accuracy: 0.9894 - val_loss: 2.4520 - val_accuracy: 0.6458\n",
            "Epoch 499/500\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 0.1540 - accuracy: 0.9788 - val_loss: 2.4886 - val_accuracy: 0.6458\n",
            "Epoch 500/500\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.1552 - accuracy: 0.9947 - val_loss: 2.6116 - val_accuracy: 0.6042\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "batch_size=32\n",
        "history = model.fit(train_dataset[0], train_dataset[1], epochs=500, callbacks = [cb], validation_data=test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "F_7ARwJF1bc5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#diisi dengan plot hasil accuray dan loss training dan testing\n",
        "\n",
        "\n",
        "# Plot utility\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "\n",
        "# Plot the accuracy\n",
        "plot_graphs(history, \"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model created\n"
          ]
        }
      ],
      "source": [
        "model.save('model.h5', history)\n",
        "print(\"model created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "RGfHnsuNz50k"
      },
      "outputs": [],
      "source": [
        "# # Membuat Input Chat\n",
        "# while True:\n",
        "#   texts_p = []\n",
        "#   prediction_input = input('👨‍🦰 Kamu : ')\n",
        "\n",
        "#   # Menghapus punktuasi dan konversi ke huruf kecil\n",
        "#   prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
        "#   prediction_input = ''.join(prediction_input)\n",
        "#   texts_p.append(prediction_input)\n",
        "\n",
        "#   # Tokenisasi dan Padding\n",
        "#   prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "#   prediction_input = np.array(prediction_input).reshape(-1)\n",
        "#   prediction_input = pad_sequences([prediction_input],max_sequence_length)\n",
        "\n",
        "#   # Mendapatkan hasil keluaran pada model\n",
        "#   output = model.predict(prediction_input)\n",
        "#   output = output.argmax()\n",
        "\n",
        "#   # Menemukan respon sesuai data tag\n",
        "#   response_tag = le.inverse_transform([output])[0]\n",
        "#   print(\"🤖 ChatbotX :\",random.choice(responses[response_tag]))\n",
        "#   if response_tag == \"goodbye\":\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "EcbkYO1h1lvG"
      },
      "outputs": [],
      "source": [
        "# #diisi dengan save model h5 dan converter tflite\n",
        "# import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "gg8vshaHBT_i"
      },
      "outputs": [],
      "source": [
        "# # Save the model to a file\n",
        "# joblib.dump(model, 'chatbot_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Save the model to a file\n",
        "# joblib.dump(history, 'history_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "cw27AehiBXXs"
      },
      "outputs": [],
      "source": [
        "# # Load the model from the file\n",
        "# chatbot_model = joblib.load('chatbot_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcBd0THIBYaT",
        "outputId": "711e3a96-0fd6-48de-e205-d518ab7ffb2c"
      },
      "outputs": [],
      "source": [
        "# print(chatbot_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhxU2_VxCeIL",
        "outputId": "9e262811-c56e-4e4c-ba86-d541aa1da9d4"
      },
      "outputs": [],
      "source": [
        "# # Membuat Input Chat\n",
        "# while True:\n",
        "#   texts_p = []\n",
        "#   prediction_input = input('👨‍🦰 Kamu : ')\n",
        "\n",
        "#   # Menghapus punktuasi dan konversi ke huruf kecil\n",
        "#   prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
        "#   prediction_input = ''.join(prediction_input)\n",
        "#   texts_p.append(prediction_input)\n",
        "\n",
        "#   # Tokenisasi dan Padding\n",
        "#   prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "#   prediction_input = np.array(prediction_input).reshape(-1)\n",
        "#   prediction_input = pad_sequences([prediction_input],max_sequence_length)\n",
        "\n",
        "#   # Mendapatkan hasil keluaran pada model\n",
        "#   output = chatbot_model.predict(prediction_input)\n",
        "#   output = output.argmax()\n",
        "\n",
        "#   # Menemukan respon sesuai data tag\n",
        "#   response_tag = le.inverse_transform([output])[0]\n",
        "#   print(\"🤖 ChatbotX :\",random.choice(responses[response_tag]))\n",
        "#   if response_tag == \"goodbye\":\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCTItDQrIrkY",
        "outputId": "5079ef12-0be9-48a7-d179-721f90321d02"
      },
      "outputs": [],
      "source": [
        "# from flask import Flask, render_template, request\n",
        "# import numpy as np\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# import random\n",
        "# import string\n",
        "\n",
        "# app = Flask(__name__)\n",
        "\n",
        "# # Define your model and tokenizer here\n",
        "# # chatbot_model = 'chatbot_model'\n",
        "# # tokenizer = ''\n",
        "# # max_sequence_length = ''\n",
        "# # le = ''\n",
        "# # responses = ''\n",
        "\n",
        "# @app.route('/')\n",
        "# def home():\n",
        "#     return \"hey\"\n",
        "\n",
        "# @app.route('/chat', methods=['POST'])\n",
        "# def chat():\n",
        "#     texts_p = []\n",
        "#     prediction_input = request.form['message']\n",
        "\n",
        "#     # Remove punctuation and convert to lowercase\n",
        "#     prediction_input = [letter.lower() for letter in prediction_input if letter not in string.punctuation]\n",
        "#     prediction_input = ''.join(prediction_input)\n",
        "#     texts_p.append(prediction_input)\n",
        "\n",
        "#     # Tokenize and pad the input\n",
        "#     prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "#     prediction_input = np.array(prediction_input).reshape(-1)\n",
        "#     prediction_input = pad_sequences([prediction_input], max_sequence_length)\n",
        "\n",
        "#     # Get the model's output prediction\n",
        "#     output = chatbot_model.predict(prediction_input)\n",
        "#     output = output.argmax()\n",
        "\n",
        "#     # Find the corresponding response based on the predicted tag\n",
        "#     response_tag = le.inverse_transform([output])[0]\n",
        "#     response = random.choice(responses[response_tag])\n",
        "\n",
        "#     return {'response': response}\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     app.run()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
